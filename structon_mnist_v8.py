#!/usr/bin/env python3
"""
Structon Vision v8.0 - ç»Ÿä¸€æ¶æ„

æ ¸å¿ƒç®€åŒ–ï¼š
- ä¸å†åŒºåˆ† Atomic å’Œ Wrapper
- æ¯ä¸ª Structon æ—¢æ˜¯è¯†åˆ«å™¨åˆæ˜¯è·¯ç”±å™¨
- Structon: "è¿™æ˜¯æˆ‘çš„å—ï¼Ÿæ˜¯â†’è¾“å‡ºlabelï¼Œä¸æ˜¯â†’äº¤ç»™å·¦å­©å­"

ç»“æ„ï¼š
S9 (label='9')
â”œâ”€ [æ˜¯ 9] â†’ è¾“å‡º "9"
â””â”€ [ä¸æ˜¯ 9] â†’ S8 (label='8')
                â”œâ”€ [æ˜¯ 8] â†’ è¾“å‡º "8"
                â””â”€ [ä¸æ˜¯ 8] â†’ S7 ...
                                â””â”€ S1 (label='1')
                                    â”œâ”€ [æ˜¯ 1] â†’ è¾“å‡º "1"
                                    â””â”€ [ä¸æ˜¯ 1] â†’ S0 (label='0')
                                                    â””â”€ è¾“å‡º "0"ï¼ˆå¶å­ï¼‰
"""

import numpy as np
from typing import Optional, Tuple, List
import time
import gzip
import os
import urllib.request


# =============================================================================
# 1. MNIST åŠ è½½
# =============================================================================

def load_mnist():
    """åŠ è½½ MNIST æ•°æ®é›†"""
    base_url = 'https://storage.googleapis.com/cvdf-datasets/mnist/'
    files = {
        'train_images': 'train-images-idx3-ubyte.gz',
        'train_labels': 'train-labels-idx1-ubyte.gz',
        'test_images': 't10k-images-idx3-ubyte.gz',
        'test_labels': 't10k-labels-idx1-ubyte.gz'
    }
    
    data = {}
    mnist_dir = os.path.expanduser('~/.mnist')
    os.makedirs(mnist_dir, exist_ok=True)
    
    for key, filename in files.items():
        filepath = os.path.join(mnist_dir, filename)
        if not os.path.exists(filepath):
            print(f"Downloading {filename}...")
            urllib.request.urlretrieve(base_url + filename, filepath)
        
        with gzip.open(filepath, 'rb') as f:
            if 'images' in key:
                f.read(16)
                data[key] = np.frombuffer(f.read(), dtype=np.uint8).reshape(-1, 28, 28)
            else:
                f.read(8)
                data[key] = np.frombuffer(f.read(), dtype=np.uint8)
    
    return data['train_images'], data['train_labels'], data['test_images'], data['test_labels']


# =============================================================================
# 2. ç‰¹å¾æå–
# =============================================================================

class StateExtractor:
    """ç®€å•çš„ç‰¹å¾æå–å™¨ï¼š5x5 ä¸‹é‡‡æ ·"""
    
    def extract(self, image: np.ndarray) -> np.ndarray:
        img = image.astype(np.float32) / 255.0
        
        # 5x5 ä¸‹é‡‡æ ·
        h, w = img.shape
        bh, bw = h // 5, w // 5
        features = []
        for i in range(5):
            for j in range(5):
                block = img[i*bh:(i+1)*bh, j*bw:(j+1)*bw]
                features.append(np.mean(block))
        
        state = np.array(features, dtype=np.float32)
        
        # å½’ä¸€åŒ–
        norm = np.linalg.norm(state)
        if norm > 1e-6:
            state = state / norm
        
        return state


# =============================================================================
# 3. Local Resonant Memory (LRM)
# =============================================================================

class LRM:
    """
    Local Resonant Memory
    
    ç®€åŒ–ç‰ˆï¼š
    - 2 ä¸ªåŠ¨ä½œï¼š[æ˜¯æˆ‘çš„, ä¸æ˜¯æˆ‘çš„]
    - åŸºäºä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…
    """
    
    def __init__(
        self,
        state_dim: int = 25,
        capacity: int = 200,
        key_dim: int = 16,
        similarity_threshold: float = 0.95,
        learning_rate: float = 0.3
    ):
        self.state_dim = state_dim
        self.capacity = capacity
        self.key_dim = key_dim
        self.similarity_threshold = similarity_threshold
        self.learning_rate = learning_rate
        self.n_actions = 2  # [æ˜¯, ä¸æ˜¯]
        
        # éšæœºæŠ•å½±çŸ©é˜µ
        self.projection = np.random.randn(state_dim, key_dim).astype(np.float32)
        self.projection /= np.linalg.norm(self.projection, axis=0, keepdims=True)
        
        # è®°å¿†å­˜å‚¨
        self.keys: List[np.ndarray] = []
        self.values: List[np.ndarray] = []  # Q-values for each action
        self.access_counts: List[int] = []
        
        self.frozen = False
    
    def _compute_key(self, state: np.ndarray) -> np.ndarray:
        key = state @ self.projection
        norm = np.linalg.norm(key)
        if norm > 1e-6:
            key = key / norm
        return key
    
    def query(self, state: np.ndarray) -> Tuple[np.ndarray, float]:
        """æŸ¥è¯¢çŠ¶æ€å¯¹åº”çš„ Q å€¼"""
        key = self._compute_key(state)
        
        if len(self.keys) == 0:
            return np.zeros(self.n_actions, dtype=np.float32), 0.0
        
        key_matrix = np.array(self.keys)
        scores = key_matrix @ key
        
        # åŠ æƒå¹³å‡
        weights = np.maximum(scores, 0) ** 2
        weight_sum = np.sum(weights)
        
        if weight_sum < 1e-6:
            return np.zeros(self.n_actions, dtype=np.float32), 0.0
        
        weights = weights / weight_sum
        q_values = np.zeros(self.n_actions, dtype=np.float32)
        for i, w in enumerate(weights):
            if w > 0.01:
                q_values += w * self.values[i]
        
        confidence = float(np.max(scores))
        return q_values, confidence
    
    def remember(self, state: np.ndarray, action: int, target_q: float) -> str:
        """è®°ä½ç»éªŒ"""
        if self.frozen:
            return 'frozen'
        
        key = self._compute_key(state)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼è®°å¿†
        if len(self.keys) > 0:
            key_matrix = np.array(self.keys)
            scores = key_matrix @ key
            best_idx = int(np.argmax(scores))
            best_score = float(scores[best_idx])
            
            if best_score > self.similarity_threshold:
                # æ›´æ–°ç°æœ‰è®°å¿†
                old_q = self.values[best_idx][action]
                self.values[best_idx][action] = old_q + self.learning_rate * (target_q - old_q)
                self.access_counts[best_idx] += 1
                return 'update'
        
        # åˆ›å»ºæ–°è®°å¿†
        if len(self.keys) > 0:
            new_q, _ = self.query(state)
            new_q = new_q.copy()
        else:
            new_q = np.zeros(self.n_actions, dtype=np.float32)
        new_q[action] = target_q
        
        # å®¹é‡ç®¡ç†
        if len(self.keys) >= self.capacity:
            min_idx = int(np.argmin(self.access_counts))
            self.keys.pop(min_idx)
            self.values.pop(min_idx)
            self.access_counts.pop(min_idx)
        
        self.keys.append(key.copy())
        self.values.append(new_q)
        self.access_counts.append(1)
        
        return 'new'
    
    def freeze(self):
        self.frozen = True
    
    @property
    def size(self) -> int:
        return len(self.keys)


# =============================================================================
# 4. ç»Ÿä¸€çš„ Structon
# =============================================================================

class Structon:
    """
    ç»Ÿä¸€çš„ Structon - æ—¢æ˜¯è¯†åˆ«å™¨åˆæ˜¯è·¯ç”±å™¨
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    - "è¿™æ˜¯æˆ‘çš„å—ï¼Ÿ"
    - æ˜¯ â†’ è¾“å‡º self.label
    - ä¸æ˜¯ â†’ äº¤ç»™ left_child ç»§ç»­åˆ¤æ–­
    
    LRM å­¦ä¹ ï¼š
    - action[0]: æ˜¯æˆ‘çš„
    - action[1]: ä¸æ˜¯æˆ‘çš„
    """
    
    _id_counter = 0
    
    def __init__(
        self,
        label: str,
        left_child: Optional['Structon'] = None,
        state_dim: int = 25,
        capacity: int = 200,
        key_dim: int = 16
    ):
        Structon._id_counter += 1
        self.id = f"S{Structon._id_counter:03d}"
        
        self.label = label
        self.left_child = left_child  # None è¡¨ç¤ºå¶å­èŠ‚ç‚¹
        
        self.state_dim = state_dim
        self.capacity = capacity
        self.key_dim = key_dim
        
        self.lrm = LRM(
            state_dim=state_dim,
            capacity=capacity,
            key_dim=key_dim
        )
        
        self.frozen = False
        
        # ç»Ÿè®¡
        self.total_executes = 0
        self.total_learns = 0
        
        # è¿½è¸ªå­¦ä¹ æ•ˆæœ
        self.history = []  # æœ€è¿‘çš„æ­£ç¡®/é”™è¯¯è®°å½•
        self.history_window = 20
    
    def execute(self, state: np.ndarray) -> Tuple[Optional[str], float]:
        """
        æ‰§è¡Œåˆ¤æ–­
        
        Returns:
            label: è¯†åˆ«ç»“æœ
            confidence: ç½®ä¿¡åº¦
        """
        self.total_executes += 1
        
        q_values, confidence = self.lrm.query(state)
        
        if q_values[0] > q_values[1]:  # action=0: æ˜¯æˆ‘çš„
            return self.label, confidence
        else:  # action=1: ä¸æ˜¯æˆ‘çš„
            if self.left_child is not None:
                return self.left_child.execute(state)
            else:
                # å¶å­èŠ‚ç‚¹ï¼Œé»˜è®¤è¿”å›è‡ªå·±ï¼ˆæœ€åçš„é€‰æ‹©ï¼‰
                return self.label, confidence * 0.5
    
    def learn(self, state: np.ndarray, true_label: str) -> bool:
        """
        å­¦ä¹ 
        
        Returns:
            correct: è¿™æ¬¡åˆ¤æ–­æ˜¯å¦æ­£ç¡®
        """
        self.total_learns += 1
        
        is_mine = (true_label == self.label)
        
        # å…ˆæ‰§è¡Œçœ‹å½“å‰åˆ¤æ–­
        q_values, _ = self.lrm.query(state)
        predicted_mine = (q_values[0] > q_values[1])
        
        # è®¡ç®—æ­£ç¡®æ€§
        if is_mine:
            correct = predicted_mine  # åº”è¯¥è¯´"æ˜¯æˆ‘çš„"
        else:
            correct = not predicted_mine  # åº”è¯¥è¯´"ä¸æ˜¯æˆ‘çš„"
        
        # å­¦ä¹ 
        if is_mine:
            # è¿™æ˜¯æˆ‘çš„ï¼å¼ºåŒ– "æ˜¯"
            self.lrm.remember(state, action=0, target_q=1.0)
            self.lrm.remember(state, action=1, target_q=-0.5)
        else:
            # ä¸æ˜¯æˆ‘çš„ï¼å¼ºåŒ– "ä¸æ˜¯"
            self.lrm.remember(state, action=1, target_q=1.0)
            self.lrm.remember(state, action=0, target_q=-0.5)
        
        # é€’å½’è®©å·¦å­©å­ä¹Ÿå­¦ä¹ 
        if self.left_child is not None:
            self.left_child.learn(state, true_label)
        
        # è®°å½•å†å²
        self.history.append(1 if correct else 0)
        if len(self.history) > self.history_window * 2:
            self.history = self.history[-self.history_window:]
        
        return correct
    
    def get_accuracy(self) -> float:
        """è·å–æœ€è¿‘çš„å‡†ç¡®ç‡"""
        if len(self.history) < self.history_window:
            return 0.0
        recent = self.history[-self.history_window:]
        return sum(recent) / len(recent)
    
    def freeze(self):
        """å†»ç»“ï¼ˆåœæ­¢å­¦ä¹ ï¼‰"""
        self.frozen = True
        self.lrm.freeze()
        if self.left_child is not None:
            self.left_child.freeze()
    
    def depth(self) -> int:
        """æ ‘æ·±åº¦"""
        if self.left_child is None:
            return 1
        return 1 + self.left_child.depth()
    
    def count_nodes(self) -> int:
        """èŠ‚ç‚¹æ€»æ•°"""
        if self.left_child is None:
            return 1
        return 1 + self.left_child.count_nodes()
    
    def total_memories(self) -> int:
        """æ€»è®°å¿†æ•°"""
        total = self.lrm.size
        if self.left_child is not None:
            total += self.left_child.total_memories()
        return total
    
    def print_tree(self, indent: int = 0):
        """æ‰“å°æ ‘ç»“æ„"""
        prefix = "  " * indent
        icon = "â„ï¸" if self.frozen else "ğŸ”¥"
        acc = self.get_accuracy() * 100
        print(f"{prefix}{icon} {self.id} [label='{self.label}'] "
              f"mem:{self.lrm.size}/{self.capacity} acc:{acc:.0f}%")
        if self.left_child is not None:
            print(f"{prefix}  â””â”€[ä¸æ˜¯{self.label}]:")
            self.left_child.print_tree(indent + 2)


# =============================================================================
# 5. Vision System
# =============================================================================

class StructonVisionSystem:
    """
    Structon è§†è§‰ç³»ç»Ÿ v8
    
    ç®€åŒ–ç‰ˆï¼šåªæœ‰ä¸€ç§ Structonï¼Œå‘ä¸Šç”Ÿé•¿
    """
    
    def __init__(
        self,
        state_dim: int = 25,
        capacity: int = 200,
        key_dim: int = 16
    ):
        self.extractor = StateExtractor()
        self.state_dim = state_dim
        self.capacity = capacity
        self.key_dim = key_dim
        
        self.root: Optional[Structon] = None
        self.promote_count = 0
    
    def add_class(self, label: str):
        """
        æ·»åŠ æ–°ç±»åˆ«
        
        åˆ›å»ºæ–°çš„ Structonï¼ŒæŠŠæ—§çš„ä½œä¸º left_child
        """
        self.promote_count += 1
        
        new_structon = Structon(
            label=label,
            left_child=self.root,  # æ—§ root å˜æˆ left_child
            state_dim=self.state_dim,
            capacity=self.capacity,
            key_dim=self.key_dim
        )
        
        self.root = new_structon
        print(f"  + æ·»åŠ  Structon label='{label}', æ€»æ•°: {self.promote_count}")
    
    def predict(self, image: np.ndarray) -> Tuple[str, float]:
        """é¢„æµ‹"""
        if self.root is None:
            return "?", 0.0
        
        state = self.extractor.extract(image)
        result, confidence = self.root.execute(state)
        
        return result if result else "?", confidence
    
    def train(self, image: np.ndarray, label: str) -> bool:
        """è®­ç»ƒä¸€ä¸ªæ ·æœ¬"""
        if self.root is None:
            return False
        
        state = self.extractor.extract(image)
        return self.root.learn(state, label)
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("Structon Vision System v8.0")
        print("=" * 60)
        
        if self.root is None:
            print("(ç©º)")
            return
        
        print(f"ç±»åˆ«æ•°: {self.promote_count}")
        print(f"æ·±åº¦: {self.root.depth()}")
        print(f"èŠ‚ç‚¹æ•°: {self.root.count_nodes()}")
        print(f"æ€»è®°å¿†: {self.root.total_memories()}")
        
        print("\n=== æ ‘ç»“æ„ ===")
        self.root.print_tree()


# =============================================================================
# 6. å®éªŒ
# =============================================================================

def run_experiment(
    n_per_class: int = 200,
    n_test: int = 500,
    capacity: int = 200,
    key_dim: int = 16,
    target_accuracy: float = 0.90,
    max_epochs: int = 30,
    min_epochs: int = 3
):
    """è¿è¡Œå®éªŒ"""
    print("=" * 70)
    print("Structon Vision v8.0 - ç»Ÿä¸€æ¶æ„")
    print("=" * 70)
    print(f"\nå‚æ•°:")
    print(f"  capacity={capacity}, key_dim={key_dim}")
    print(f"  target_accuracy={target_accuracy}")
    print(f"  max_epochs={max_epochs}, min_epochs={min_epochs}")
    print(f"  æ¯ç±»è®­ç»ƒ: {n_per_class}, æµ‹è¯•: {n_test}")
    
    print("\næ ¸å¿ƒè®¾è®¡:")
    print("  - æ¯ä¸ª Structon æ—¢æ˜¯è¯†åˆ«å™¨åˆæ˜¯è·¯ç”±å™¨")
    print("  - 'æ˜¯æˆ‘çš„' â†’ è¾“å‡º label")
    print("  - 'ä¸æ˜¯æˆ‘çš„' â†’ äº¤ç»™ left_child")
    
    print("\nLoading MNIST...")
    train_images, train_labels, test_images, test_labels = load_mnist()
    
    system = StructonVisionSystem(
        state_dim=25,
        capacity=capacity,
        key_dim=key_dim
    )
    
    # å‡†å¤‡æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬
    class_samples = {}
    for digit in range(10):
        indices = np.where(train_labels == digit)[0][:n_per_class]
        np.random.shuffle(indices)
        class_samples[digit] = [(train_images[i], str(digit)) for i in indices]
    
    print(f"\n=== é€ç±»å¢é‡å­¦ä¹  ===")
    t0 = time.time()
    
    total_samples_used = 0
    
    for current_digit in range(10):
        print(f"\n--- é˜¶æ®µ {current_digit}: å­¦ä¹ æ•°å­— {current_digit} ---")
        
        # 1. æ·»åŠ æ–°ç±»åˆ«
        system.add_class(str(current_digit))
        
        # 2. å‡†å¤‡è®­ç»ƒæ ·æœ¬ï¼šæ‰€æœ‰å·²å­¦æ•°å­—
        train_samples = []
        for digit in range(current_digit + 1):
            train_samples.extend(class_samples[digit])
        
        print(f"  è®­ç»ƒæ ·æœ¬: {len(train_samples)} (æ•°å­— 0-{current_digit})")
        
        # 3. è®­ç»ƒç›´åˆ°å‡†ç¡®ç‡è¾¾æ ‡
        epoch = 0
        best_acc = 0.0
        
        while epoch < max_epochs:
            epoch += 1
            np.random.shuffle(train_samples)
            
            epoch_correct = 0
            for img, label in train_samples:
                state = system.extractor.extract(img)
                result, conf = system.root.execute(state)
                if result == label:
                    epoch_correct += 1
                system.train(img, label)
                total_samples_used += 1
            
            acc = epoch_correct / len(train_samples) * 100
            best_acc = max(best_acc, acc)
            
            # æ¯ 5 è½®æˆ–è¾¾æ ‡æ—¶æ‰“å°
            if epoch % 5 == 0 or acc >= target_accuracy * 100:
                print(f"    è½®æ¬¡ {epoch}: å‡†ç¡®ç‡ {acc:.1f}%")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾æ ‡
            if epoch >= min_epochs and acc >= target_accuracy * 100:
                print(f"  âœ“ è¾¾æ ‡! å‡†ç¡®ç‡ {acc:.1f}% >= {target_accuracy*100}%")
                break
        
        if epoch >= max_epochs:
            print(f"  âœ— è¾¾åˆ°æœ€å¤§è½®æ•°ï¼Œæœ€ä½³å‡†ç¡®ç‡ {best_acc:.1f}%")
    
    print(f"\nè®­ç»ƒå®Œæˆ: {time.time()-t0:.1f}ç§’")
    print(f"æ€»æ ·æœ¬: {total_samples_used}")
    
    system.print_stats()
    
    # æµ‹è¯•
    print(f"\n=== æµ‹è¯• {n_test} æ ·æœ¬ ===")
    results = {str(d): {'correct': 0, 'total': 0} for d in range(10)}
    test_indices = np.random.choice(len(test_images), n_test, replace=False)
    
    t0 = time.time()
    for idx in test_indices:
        predicted, confidence = system.predict(test_images[idx])
        true_label = str(test_labels[idx])
        
        results[true_label]['total'] += 1
        if predicted == true_label:
            results[true_label]['correct'] += 1
    
    print(f"æµ‹è¯•å®Œæˆ: {time.time()-t0:.1f}ç§’")
    
    total_correct = sum(r['correct'] for r in results.values())
    total_samples = sum(r['total'] for r in results.values())
    
    print(f"\næ€»å‡†ç¡®ç‡: {total_correct/total_samples*100:.1f}%")
    print("\nå„æ•°å­—:")
    for d in range(10):
        r = results[str(d)]
        if r['total'] > 0:
            acc = r['correct'] / r['total'] * 100
            print(f"  {d}: {acc:.1f}% ({r['correct']}/{r['total']})")
    
    return system


# =============================================================================
# ä¸»å…¥å£
# =============================================================================

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--per-class', type=int, default=200)
    parser.add_argument('--test', type=int, default=500)
    parser.add_argument('--capacity', type=int, default=200)
    parser.add_argument('--key-dim', type=int, default=16)
    parser.add_argument('--target-acc', type=float, default=0.90)
    parser.add_argument('--max-epochs', type=int, default=30)
    parser.add_argument('--min-epochs', type=int, default=3)
    args = parser.parse_args()
    
    run_experiment(
        n_per_class=args.per_class,
        n_test=args.test,
        capacity=args.capacity,
        key_dim=args.key_dim,
        target_accuracy=args.target_acc,
        max_epochs=args.max_epochs,
        min_epochs=args.min_epochs
    )
