"""
Structon Vision v7.21 - çœŸæ­£çš„ Bottom-Up åˆ†å½¢æ¶æ„
=================================================

æ ¸å¿ƒä¿®å¤ï¼š
1. åŠ¨æ€æ™‹å‡ï¼šè®°å¿†æ»¡äº† â†’ å†»ç»“ â†’ åˆ›å»º Wrapper â†’ ç»§ç»­ç”Ÿé•¿
2. è·¯ç”±å³åŠ¨ä½œï¼šWrapper å­¦ä¹  "é€ç»™å“ªä¸ª child"ï¼Œä¸å­¦æ ‡ç­¾
3. å¼ºåŒ–åé¦ˆï¼šchild é¢„æµ‹å¯¹äº† â†’ å¼ºåŒ–è·¯ç”±ï¼›é”™äº† â†’ å¼±åŒ–è·¯ç”±

è®¾è®¡å“²å­¦ï¼š
- Wrapper ä¸çŸ¥é“åº•å±‚æ•°å­—æ˜¯å‡ 
- Wrapper åªçŸ¥é“ "è¿™ä¸ª pattern é€ç»™ Child_A é€šå¸¸å¾—åˆ°å¥½ç»“æœ"
- ç»“æ„è‡ªåŠ¨ç”Ÿé•¿ï¼ŒçŸ¥è¯†æ°¸ä¸ä¸¢å¤±

Author: Structon Framework
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass, field
import os
import gzip
import struct
import urllib.request
import time


# =============================================================================
# 1. MNIST åŠ è½½
# =============================================================================

def load_mnist(path='./mnist_data'):
    """åŠ è½½ MNIST æ•°æ®é›†"""
    os.makedirs(path, exist_ok=True)
    
    base_url = 'http://yann.lecun.com/exdb/mnist/'
    files = {
        'train_images': 'train-images-idx3-ubyte.gz',
        'train_labels': 'train-labels-idx1-ubyte.gz',
        'test_images': 't10k-images-idx3-ubyte.gz',
        'test_labels': 't10k-labels-idx1-ubyte.gz'
    }
    
    for name, filename in files.items():
        filepath = os.path.join(path, filename)
        if not os.path.exists(filepath):
            print(f"Downloading {filename}...")
            urllib.request.urlretrieve(base_url + filename, filepath)
    
    def read_images(filepath):
        with gzip.open(filepath, 'rb') as f:
            magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
            images = np.frombuffer(f.read(), dtype=np.uint8)
            return images.reshape(num, rows, cols)
    
    def read_labels(filepath):
        with gzip.open(filepath, 'rb') as f:
            magic, num = struct.unpack('>II', f.read(8))
            return np.frombuffer(f.read(), dtype=np.uint8)
    
    train_images = read_images(os.path.join(path, files['train_images']))
    train_labels = read_labels(os.path.join(path, files['train_labels']))
    test_images = read_images(os.path.join(path, files['test_images']))
    test_labels = read_labels(os.path.join(path, files['test_labels']))
    
    return train_images, train_labels, test_images, test_labels


# =============================================================================
# 2. ç‰¹å¾æå–å™¨
# =============================================================================

class StateExtractor:
    """æå– MNIST å›¾åƒçš„çŠ¶æ€ç‰¹å¾"""
    
    def __init__(self):
        self.feature_dim = 25
    
    def extract(self, image: np.ndarray) -> np.ndarray:
        """æå– 25 ç»´ç‰¹å¾"""
        img = image.astype(np.float32) / 255.0
        binary = (img > 0.3).astype(np.float32)
        
        features = []
        
        # 1. æ‹“æ‰‘ç‰¹å¾ (4D)
        n_holes = self._count_holes(binary)
        endpoints = self._find_endpoints(binary)
        junctions = self._find_junctions(binary)
        is_closed = 1.0 if n_holes > 0 else 0.0
        
        features.extend([
            n_holes / 3.0,
            len(endpoints) / 5.0,
            len(junctions) / 3.0,
            is_closed
        ])
        
        # 2. ç«¯ç‚¹ä½ç½® (9D)
        ep_regions = np.zeros(9)
        for y, x in endpoints:
            ry, rx = min(2, y // 10), min(2, x // 10)
            ep_regions[ry * 3 + rx] = 1.0
        features.extend(ep_regions)
        
        # 3. äº¤å‰ç‚¹ä½ç½® (3D)
        jc_regions = np.zeros(3)
        for y, x in junctions:
            region = min(2, y // 10)
            jc_regions[region] = 1.0
        features.extend(jc_regions)
        
        # 4. è¾¹ç¼˜æ–¹å‘ (4D)
        h_top = np.sum(binary[:10, :]) / (10 * 28)
        h_bottom = np.sum(binary[18:, :]) / (10 * 28)
        v_left = np.sum(binary[:, :10]) / (28 * 10)
        v_right = np.sum(binary[:, 18:]) / (28 * 10)
        features.extend([h_top, h_bottom, v_left, v_right])
        
        # 5. å¯†åº¦åˆ†å¸ƒ (3D)
        density_top = np.sum(binary[:9, :]) / (9 * 28)
        density_mid = np.sum(binary[9:18, :]) / (9 * 28)
        density_bottom = np.sum(binary[18:, :]) / (10 * 28)
        features.extend([density_top, density_mid, density_bottom])
        
        # 6. è´¨å¿ƒ (2D)
        ys, xs = np.where(binary > 0)
        if len(xs) > 0:
            cx, cy = np.mean(xs) / 28.0, np.mean(ys) / 28.0
        else:
            cx, cy = 0.5, 0.5
        features.extend([cx, cy])
        
        return np.array(features, dtype=np.float32)
    
    def _count_holes(self, binary: np.ndarray) -> int:
        from collections import deque
        
        padded = np.pad(binary, 1, mode='constant', constant_values=0)
        visited = np.zeros_like(padded, dtype=bool)
        
        queue = deque([(0, 0)])
        visited[0, 0] = True
        
        while queue:
            y, x = queue.popleft()
            for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
                ny, nx = y + dy, x + dx
                if 0 <= ny < padded.shape[0] and 0 <= nx < padded.shape[1]:
                    if not visited[ny, nx] and padded[ny, nx] == 0:
                        visited[ny, nx] = True
                        queue.append((ny, nx))
        
        holes = 0
        for y in range(1, padded.shape[0] - 1):
            for x in range(1, padded.shape[1] - 1):
                if padded[y, x] == 0 and not visited[y, x]:
                    holes += 1
                    queue = deque([(y, x)])
                    visited[y, x] = True
                    while queue:
                        cy, cx = queue.popleft()
                        for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
                            ny, nx = cy + dy, cx + dx
                            if not visited[ny, nx] and padded[ny, nx] == 0:
                                visited[ny, nx] = True
                                queue.append((ny, nx))
        
        return holes
    
    def _find_endpoints(self, binary: np.ndarray) -> List[Tuple[int, int]]:
        endpoints = []
        skeleton = binary.copy()
        
        for y in range(1, binary.shape[0] - 1):
            for x in range(1, binary.shape[1] - 1):
                if skeleton[y, x] > 0:
                    neighbors = np.sum(skeleton[y-1:y+2, x-1:x+2]) - skeleton[y, x]
                    if neighbors == 1:
                        endpoints.append((y, x))
        
        return endpoints[:5]
    
    def _find_junctions(self, binary: np.ndarray) -> List[Tuple[int, int]]:
        junctions = []
        skeleton = binary.copy()
        
        for y in range(1, binary.shape[0] - 1):
            for x in range(1, binary.shape[1] - 1):
                if skeleton[y, x] > 0:
                    neighbors = np.sum(skeleton[y-1:y+2, x-1:x+2]) - skeleton[y, x]
                    if neighbors >= 3:
                        junctions.append((y, x))
        
        return junctions[:3]


# =============================================================================
# 3. å…±æŒ¯è®°å¿† (Resonant Memory)
# =============================================================================

class ResonantMemory:
    """
    å…±æŒ¯è®°å¿†ï¼šåŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„æ— æ¢¯åº¦å­¦ä¹ 
    
    å­˜å‚¨ key â†’ Q-values æ˜ å°„
    Q-values é•¿åº¦ = n_actionsï¼ˆchildren æ•°é‡ï¼‰
    """
    
    def __init__(
        self,
        key_dim: int,
        n_actions: int,
        capacity: int = 50,
        temperature: float = 0.1,
        lr: float = 0.3,
        similarity_threshold: float = 0.7
    ):
        self.key_dim = key_dim
        self.n_actions = n_actions
        self.capacity = capacity
        self.temperature = temperature
        self.lr = lr
        self.similarity_threshold = similarity_threshold
        
        # è®°å¿†å­˜å‚¨
        self.keys: List[np.ndarray] = []
        self.values: List[np.ndarray] = []
        self.access_counts: List[int] = []
        
        # å†»ç»“çŠ¶æ€
        self.frozen: bool = False
        
        # ç»Ÿè®¡
        self.total_queries = 0
        self.total_updates = 0
    
    def query(self, key: np.ndarray) -> Tuple[np.ndarray, float, int]:
        """
        å…±æŒ¯æŸ¥è¯¢
        
        Returns:
            q_values: å„ action çš„ Q å€¼
            confidence: ç½®ä¿¡åº¦
            best_match_idx: æœ€ä½³åŒ¹é…çš„è®°å¿†ç´¢å¼•ï¼ˆ-1 è¡¨ç¤ºæ— åŒ¹é…ï¼‰
        """
        self.total_queries += 1
        
        if len(self.keys) == 0:
            return np.zeros(self.n_actions, dtype=np.float32), 0.0, -1
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        key_matrix = np.array(self.keys)
        scores = key_matrix @ key
        
        best_idx = int(np.argmax(scores))
        max_score = float(scores[best_idx])
        
        # Softmax åŠ æƒ
        exp_scores = np.exp((scores - max_score) / self.temperature)
        weights = exp_scores / (np.sum(exp_scores) + 1e-8)
        
        # åŠ æƒæ±‚å’Œå¾—åˆ° Q-values
        value_matrix = np.array(self.values)
        q_values = weights @ value_matrix
        
        # æ›´æ–°è®¿é—®è®¡æ•°
        self.access_counts[best_idx] += 1
        
        # ç½®ä¿¡åº¦
        confidence = max(0.0, min(1.0, (max_score - 0.3) / 0.5))
        
        return q_values.astype(np.float32), confidence, best_idx
    
    def remember(
        self,
        key: np.ndarray,
        action: int,
        reward: float
    ) -> str:
        """
        å†™å…¥è®°å¿†ï¼ˆTD æ›´æ–°ï¼‰
        
        Args:
            key: ç¼–ç åçš„ pattern
            action: é€‰æ‹©çš„åŠ¨ä½œï¼ˆchild ç´¢å¼•ï¼‰
            reward: å¥–åŠ±ï¼ˆ+1 æ­£ç¡®ï¼Œ-1 é”™è¯¯ï¼Œ0 ä¸­æ€§ï¼‰
        
        Returns:
            'update' / 'new' / 'frozen'
        """
        if self.frozen:
            return 'frozen'
        
        self.total_updates += 1
        
        # æŸ¥æ‰¾ç›¸ä¼¼è®°å¿†
        best_idx = -1
        best_score = -1.0
        
        if len(self.keys) > 0:
            key_matrix = np.array(self.keys)
            scores = key_matrix @ key
            best_idx = int(np.argmax(scores))
            best_score = float(scores[best_idx])
            
            if best_score < self.similarity_threshold:
                best_idx = -1
        
        if best_idx >= 0:
            # æ›´æ–°ç°æœ‰è®°å¿†çš„ Q-value
            old_q = self.values[best_idx][action]
            # TD æ›´æ–°ï¼šQ = Q + lr * (reward - Q)
            self.values[best_idx][action] = old_q + self.lr * (reward - old_q)
            self.access_counts[best_idx] += 1
            return 'update'
        else:
            # å®¹é‡ç®¡ç†
            if len(self.keys) >= self.capacity:
                min_idx = int(np.argmin(self.access_counts))
                self.keys.pop(min_idx)
                self.values.pop(min_idx)
                self.access_counts.pop(min_idx)
            
            # åˆ›å»ºæ–°è®°å¿†
            new_q = np.zeros(self.n_actions, dtype=np.float32)
            new_q[action] = reward
            
            self.keys.append(key.copy())
            self.values.append(new_q)
            self.access_counts.append(1)
            return 'new'
    
    def freeze(self):
        self.frozen = True
    
    def unfreeze(self):
        self.frozen = False
    
    @property
    def size(self) -> int:
        return len(self.keys)
    
    def is_full(self) -> bool:
        return self.size >= self.capacity


# =============================================================================
# 4. ç»Ÿä¸€çš„ Structonï¼ˆæ”¯æŒ Bottom-Up ç”Ÿé•¿ï¼‰
# =============================================================================

class Structon:
    """
    ç»Ÿä¸€çš„ Structon - è‡ªç›¸ä¼¼åˆ†å½¢å•å…ƒ
    
    ä¸‰ç§è§’è‰²ï¼š
    - Actuator: children æ˜¯å­—ç¬¦ä¸²ï¼ˆåŠ¨ä½œï¼‰ï¼Œæ—  LRM
    - Atomic: children æ˜¯ Structonï¼ŒLRM å­¦ä¹ è·¯ç”±
    - Composite: å†»ç»“çš„ Atomicï¼Œåªè·¯ç”±ä¸å­¦ä¹ 
    
    å…³é”®ï¼šWrapper ä¸çŸ¥é“åº•å±‚æ ‡ç­¾ï¼Œåªå­¦ä¹ è·¯ç”±ç­–ç•¥
    """
    
    _id_counter = 0
    
    def __init__(
        self,
        children: List[Union[str, 'Structon']],
        capacity: int = 50,
        key_dim: int = 16,
        full_dim: int = 25,
        temperature: float = 0.1,
        lr: float = 0.3,
        similarity_threshold: float = 0.7,
        projector: np.ndarray = None
    ):
        Structon._id_counter += 1
        self.id = f"S{Structon._id_counter:03d}"
        
        self.children = children
        self.n_actions = len(children)
        
        # å‚æ•°å­˜å‚¨
        self.capacity = capacity
        self.key_dim = key_dim
        self.full_dim = full_dim
        self.temperature = temperature
        self.lr = lr
        self.similarity_threshold = similarity_threshold
        
        # éšæœºæŠ•å½±
        if projector is not None:
            self.projector = projector.copy()
        else:
            self.projector = np.random.randn(full_dim, key_dim).astype(np.float32)
            self.projector /= (np.linalg.norm(self.projector, axis=0, keepdims=True) + 1e-8)
        
        # å…±æŒ¯è®°å¿†ï¼ˆåªæœ‰é Actuator æ‰éœ€è¦ï¼‰
        if self.is_actuator():
            self.lrm = None
        else:
            self.lrm = ResonantMemory(
                key_dim=key_dim,
                n_actions=self.n_actions,
                capacity=capacity,
                temperature=temperature,
                lr=lr,
                similarity_threshold=similarity_threshold
            )
        
        # ç»Ÿè®¡
        self.total_queries = 0
        self.promotes = 0
    
    def _encode(self, pattern: np.ndarray) -> np.ndarray:
        """éšæœºæŠ•å½±ç¼–ç """
        key = pattern.astype(np.float32) @ self.projector
        norm = np.linalg.norm(key)
        if norm > 1e-8:
            key /= norm
        return key
    
    @property
    def frozen(self) -> bool:
        return self.lrm.frozen if self.lrm else False
    
    def freeze(self):
        if self.lrm:
            self.lrm.freeze()
    
    def unfreeze(self):
        if self.lrm:
            self.lrm.unfreeze()
    
    def is_actuator(self) -> bool:
        """æ˜¯å¦æ˜¯æ‰§è¡Œå™¨ï¼ˆchildren å…¨æ˜¯å­—ç¬¦ä¸²ï¼‰"""
        return all(isinstance(c, str) for c in self.children)
    
    def is_atomic(self) -> bool:
        """æ˜¯å¦æ˜¯å­¦ä¹ ä¸­çš„ä¸­é—´èŠ‚ç‚¹"""
        return not self.is_actuator() and not self.frozen
    
    def is_composite(self) -> bool:
        """æ˜¯å¦æ˜¯å†»ç»“çš„ä¸­é—´èŠ‚ç‚¹"""
        return not self.is_actuator() and self.frozen
    
    def query(self, pattern: np.ndarray) -> Tuple[int, float]:
        """
        æŸ¥è¯¢ï¼šé€‰æ‹©å“ªä¸ª child
        
        Returns:
            action_idx: é€‰æ‹©çš„ child ç´¢å¼•
            confidence: ç½®ä¿¡åº¦
        """
        self.total_queries += 1
        
        if self.is_actuator():
            # Actuatorï¼šéšæœºæˆ–é»˜è®¤é€‰æ‹©
            return 0, 1.0
        
        key = self._encode(pattern)
        q_values, confidence, _ = self.lrm.query(key)
        action_idx = int(np.argmax(q_values))
        return action_idx, confidence
    
    def execute(self, pattern: np.ndarray) -> Tuple[str, float]:
        """
        æ‰§è¡Œï¼šé€’å½’æŸ¥è¯¢ç›´åˆ°å¾—åˆ°åŠ¨ä½œ
        
        Returns:
            action: æœ€ç»ˆé€‰æ‹©çš„åŠ¨ä½œï¼ˆå­—ç¬¦ä¸²ï¼‰
            confidence: ç½®ä¿¡åº¦
        """
        if self.is_actuator():
            # Actuatorï¼šç›´æ¥è¿”å›å”¯ä¸€çš„ action
            return self.children[0], 1.0
        
        action_idx, confidence = self.query(pattern)
        child = self.children[action_idx]
        
        if isinstance(child, str):
            return child, confidence
        else:
            return child.execute(pattern)
    
    def learn(
        self,
        pattern: np.ndarray,
        reward: float,
        chosen_idx: int
    ) -> str:
        """
        å­¦ä¹ è·¯ç”±ç­–ç•¥ï¼ˆä¸æ˜¯å­¦æ ‡ç­¾ï¼ï¼‰
        
        Args:
            pattern: è¾“å…¥æ¨¡å¼
            reward: å¥–åŠ±ï¼ˆæ¥è‡ªä¸‹æ¸¸åé¦ˆï¼‰
            chosen_idx: é€‰æ‹©çš„ child ç´¢å¼•
        
        Returns:
            çŠ¶æ€ä¿¡æ¯
        """
        if self.lrm is None or self.frozen:
            return 'skip'
        
        key = self._encode(pattern)
        return self.lrm.remember(key, chosen_idx, reward)
    
    def should_promote(self) -> bool:
        """æ˜¯å¦éœ€è¦æ™‹å‡"""
        if self.lrm is None:
            return False
        return self.lrm.is_full() and not self.frozen
    
    def promote(self) -> 'Structon':
        """
        æ™‹å‡ï¼šå†»ç»“è‡ªå·±ï¼Œåˆ›å»º Wrapper
        
        è¿”å›æ–°çš„ Wrapperï¼ˆåº”è¯¥æ›¿æ¢ self æˆä¸ºæ–°çš„ rootï¼‰
        """
        self.promotes += 1
        
        # 1. å†»ç»“è‡ªå·±
        self.freeze()
        
        # 2. åˆ›å»ºç©ºçš„ siblingï¼ˆä¸åŒçš„æŠ•å½±ï¼ï¼‰
        sibling = Structon(
            children=self.children.copy() if self.is_actuator() else [c for c in self.children],
            capacity=self.capacity,
            key_dim=self.key_dim,
            full_dim=self.full_dim,
            temperature=self.temperature,
            lr=self.lr,
            similarity_threshold=self.similarity_threshold,
            projector=None  # æ–°çš„éšæœºæŠ•å½±
        )
        
        # 3. åˆ›å»º Wrapper
        wrapper = Structon(
            children=[self, sibling],  # 2 ä¸ª children
            capacity=self.capacity,
            key_dim=self.key_dim,
            full_dim=self.full_dim,
            temperature=self.temperature,
            lr=self.lr,
            similarity_threshold=self.similarity_threshold,
            projector=self.projector.copy()  # ç»§æ‰¿æŠ•å½±ï¼ˆä¿æŒè·¯ç”±ä¸€è‡´ï¼‰
        )
        
        return wrapper
    
    def count_nodes(self) -> int:
        count = 1
        for child in self.children:
            if isinstance(child, Structon):
                count += child.count_nodes()
        return count
    
    def depth(self) -> int:
        if self.is_actuator():
            return 1
        
        max_child_depth = 0
        for child in self.children:
            if isinstance(child, Structon):
                max_child_depth = max(max_child_depth, child.depth())
        
        return 1 + max_child_depth
    
    def total_memories(self) -> int:
        count = self.lrm.size if self.lrm else 0
        for child in self.children:
            if isinstance(child, Structon):
                count += child.total_memories()
        return count
    
    def print_tree(self, indent: int = 0):
        prefix = "  " * indent
        
        if self.is_actuator():
            icon = "âš¡"
            role = "Actuator"
            mem_info = f"actions={self.children}"
        elif self.frozen:
            icon = "â„ï¸"
            role = "Composite"
            mem_info = f"mem:{self.lrm.size}/{self.capacity}"
        else:
            icon = "ğŸ”¥"
            role = "Atomic"
            mem_info = f"mem:{self.lrm.size}/{self.capacity}"
        
        print(f"{prefix}{icon} {self.id} ({role}) [{mem_info}]")
        
        for child in self.children:
            if isinstance(child, Structon):
                child.print_tree(indent + 1)


# =============================================================================
# 5. Vision Systemï¼ˆæ”¯æŒ Bottom-Up ç”Ÿé•¿ï¼‰
# =============================================================================

class StructonVisionSystem:
    """
    Structon è§†è§‰ç³»ç»Ÿ - MNIST åˆ†ç±»
    
    å…³é”®æ”¹å˜ï¼š
    1. ä» 10 ä¸ª Actuator å¼€å§‹
    2. å­¦ä¹ æ—¶é€šè¿‡å¼ºåŒ–åé¦ˆè®­ç»ƒè·¯ç”±
    3. æ»¡äº†è‡ªåŠ¨ promote
    """
    
    def __init__(
        self,
        capacity: int = 50,
        key_dim: int = 16,
        full_dim: int = 25,
        temperature: float = 0.1,
        lr: float = 0.3,
        similarity_threshold: float = 0.7
    ):
        self.extractor = StateExtractor()
        
        # åˆ›å»º 10 ä¸ª Actuatorï¼ˆæ¯ä¸ªä»£è¡¨ä¸€ä¸ªæ•°å­—ï¼‰
        actuators = []
        for i in range(10):
            act = Structon(
                children=[str(i)],  # å•ä¸€åŠ¨ä½œ
                capacity=capacity,
                key_dim=key_dim,
                full_dim=full_dim
            )
            actuators.append(act)
        
        # åˆ›å»º rootï¼ˆè·¯ç”±åˆ° 10 ä¸ª Actuatorï¼‰
        self.root = Structon(
            children=actuators,
            capacity=capacity,
            key_dim=key_dim,
            full_dim=full_dim,
            temperature=temperature,
            lr=lr,
            similarity_threshold=similarity_threshold
        )
        
        # å‚æ•°
        self.capacity = capacity
        self.key_dim = key_dim
        self.full_dim = full_dim
        
        # ç»Ÿè®¡
        self.train_count = 0
        self.correct_count = 0
        self.promote_count = 0
    
    def predict(self, image: np.ndarray) -> Tuple[str, float]:
        """é¢„æµ‹"""
        state = self.extractor.extract(image)
        return self.root.execute(state)
    
    def train_one(
        self,
        image: np.ndarray,
        true_label: str,
        explore_rate: float = 0.1
    ) -> Tuple[bool, str]:
        """
        è®­ç»ƒä¸€ä¸ªæ ·æœ¬
        
        å…³é”®ï¼šç”¨å¼ºåŒ–å­¦ä¹ æ–¹å¼è®­ç»ƒè·¯ç”±
        """
        self.train_count += 1
        state = self.extractor.extract(image)
        
        # 1. æŸ¥è¯¢è·¯ç”±å†³ç­–
        chosen_idx, confidence = self.root.query(state)
        
        # 2. æ¢ç´¢ï¼šæœ‰ä¸€å®šæ¦‚ç‡éšæœºé€‰æ‹©
        if np.random.random() < explore_rate:
            chosen_idx = np.random.randint(self.root.n_actions)
        
        # 3. æ‰§è¡Œé€‰æ‹©çš„ child
        child = self.root.children[chosen_idx]
        predicted, _ = child.execute(state)
        
        # 4. è®¡ç®—å¥–åŠ±
        correct = (predicted == true_label)
        if correct:
            self.correct_count += 1
            reward = 1.0
        else:
            reward = -0.5  # æƒ©ç½šä½†ä¸è¦å¤ªé‡
        
        # 5. å­¦ä¹ è·¯ç”±å†³ç­–
        status = self.root.learn(state, reward, chosen_idx)
        
        # 6. æ£€æŸ¥æ˜¯å¦éœ€è¦ promote
        if self.root.should_promote():
            self.root = self.root.promote()
            self.promote_count += 1
            status = f"promoted ({self.promote_count})"
        
        return correct, status
    
    def print_stats(self):
        print(f"\n=== Structon Vision System ===")
        print(f"è®­ç»ƒæ ·æœ¬: {self.train_count}")
        if self.train_count > 0:
            print(f"è®­ç»ƒå‡†ç¡®ç‡: {self.correct_count/self.train_count*100:.1f}%")
        print(f"æ™‹å‡æ¬¡æ•°: {self.promote_count}")
        print(f"èŠ‚ç‚¹æ•°: {self.root.count_nodes()}")
        print(f"æ·±åº¦: {self.root.depth()}")
        print(f"æ€»è®°å¿†: {self.root.total_memories()}")
        
        print(f"\n=== æ ‘ç»“æ„ ===")
        self.root.print_tree()


# =============================================================================
# 6. å®éªŒ
# =============================================================================

def run_experiment(
    n_per_class: int = 50,
    n_test: int = 500,
    capacity: int = 50,
    key_dim: int = 16,
    temperature: float = 0.1,
    lr: float = 0.3,
    similarity_threshold: float = 0.7,
    explore_rate: float = 0.1,
    epochs: int = 3
):
    """è¿è¡Œå®éªŒ"""
    print("=" * 70)
    print("Structon Vision v7.21 - çœŸæ­£çš„ Bottom-Up åˆ†å½¢æ¶æ„")
    print("=" * 70)
    print(f"\nå‚æ•°:")
    print(f"  capacity={capacity}, key_dim={key_dim}")
    print(f"  temperature={temperature}, lr={lr}")
    print(f"  similarity_threshold={similarity_threshold}")
    print(f"  explore_rate={explore_rate}, epochs={epochs}")
    print(f"  æ¯ç±»è®­ç»ƒ: {n_per_class}, æµ‹è¯•: {n_test}")
    
    print("\næ ¸å¿ƒæ”¹å˜:")
    print("  1. åŠ¨æ€æ™‹å‡ï¼šè®°å¿†æ»¡äº† â†’ å†»ç»“ â†’ åˆ›å»º Wrapper")
    print("  2. è·¯ç”±å­¦ä¹ ï¼šWrapper å­¦ä¹ 'é€ç»™å“ªä¸ª child'ï¼Œä¸å­¦æ ‡ç­¾")
    print("  3. å¼ºåŒ–åé¦ˆï¼šchild é¢„æµ‹å¯¹äº† â†’ å¼ºåŒ–è·¯ç”±")
    
    print("\nLoading MNIST...")
    train_images, train_labels, test_images, test_labels = load_mnist()
    
    system = StructonVisionSystem(
        capacity=capacity,
        key_dim=key_dim,
        full_dim=25,
        temperature=temperature,
        lr=lr,
        similarity_threshold=similarity_threshold
    )
    
    # æ”¶é›†è®­ç»ƒæ ·æœ¬
    train_indices = []
    for digit in range(10):
        indices = np.where(train_labels == digit)[0][:n_per_class]
        train_indices.extend(indices)
    
    total_samples = len(train_indices)
    
    for epoch in range(epochs):
        print(f"\n=== Epoch {epoch+1}/{epochs} ===")
        
        # æ‰“ä¹±é¡ºåº
        np.random.shuffle(train_indices)
        
        epoch_correct = 0
        t0 = time.time()
        
        for i, idx in enumerate(train_indices):
            correct, status = system.train_one(
                train_images[idx],
                str(train_labels[idx]),
                explore_rate=explore_rate
            )
            if correct:
                epoch_correct += 1
            
            if (i + 1) % 100 == 0:
                acc = epoch_correct / (i + 1) * 100
                mem = system.root.lrm.size if system.root.lrm else 0
                print(f"  è®­ç»ƒ {i+1}/{total_samples}, "
                      f"å‡†ç¡®ç‡: {acc:.1f}%, "
                      f"è®°å¿†: {mem}/{capacity}, "
                      f"æ™‹å‡: {system.promote_count}")
        
        print(f"Epoch {epoch+1} å®Œæˆ: {time.time()-t0:.1f}ç§’, "
              f"å‡†ç¡®ç‡: {epoch_correct/total_samples*100:.1f}%")
        
        # é€æ¸é™ä½æ¢ç´¢ç‡
        explore_rate *= 0.7
    
    system.print_stats()
    
    # æµ‹è¯•
    print(f"\n=== æµ‹è¯• {n_test} æ ·æœ¬ ===")
    results = {str(d): {'correct': 0, 'total': 0} for d in range(10)}
    test_indices = np.random.choice(len(test_images), n_test, replace=False)
    
    t0 = time.time()
    for idx in test_indices:
        predicted, confidence = system.predict(test_images[idx])
        true_label = str(test_labels[idx])
        
        results[true_label]['total'] += 1
        if predicted == true_label:
            results[true_label]['correct'] += 1
    
    print(f"æµ‹è¯•å®Œæˆ: {time.time()-t0:.1f}ç§’")
    
    total_correct = sum(r['correct'] for r in results.values())
    total_samples = sum(r['total'] for r in results.values())
    
    print(f"\næ€»å‡†ç¡®ç‡: {total_correct/total_samples*100:.1f}%")
    print("\nå„æ•°å­—:")
    for d in range(10):
        r = results[str(d)]
        if r['total'] > 0:
            acc = r['correct'] / r['total'] * 100
            print(f"  {d}: {acc:.1f}% ({r['correct']}/{r['total']})")
    
    return system


# =============================================================================
# ä¸»å…¥å£
# =============================================================================

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--per-class', type=int, default=50)
    parser.add_argument('--test', type=int, default=500)
    parser.add_argument('--capacity', type=int, default=50)
    parser.add_argument('--key-dim', type=int, default=16)
    parser.add_argument('--temperature', type=float, default=0.1)
    parser.add_argument('--lr', type=float, default=0.3)
    parser.add_argument('--threshold', type=float, default=0.7)
    parser.add_argument('--explore', type=float, default=0.1)
    parser.add_argument('--epochs', type=int, default=3)
    args = parser.parse_args()
    
    run_experiment(
        n_per_class=args.per_class,
        n_test=args.test,
        capacity=args.capacity,
        key_dim=args.key_dim,
        temperature=args.temperature,
        lr=args.lr,
        similarity_threshold=args.threshold,
        explore_rate=args.explore,
        epochs=args.epochs
    )
