"""
Structon Vision v7.20 - ç»Ÿä¸€åˆ†å½¢æ¶æ„
=====================================

æ ¸å¿ƒæ”¹å˜ï¼š
1. æ¯ä¸ª Structon ç»“æ„ç›¸åŒï¼ˆè‡ªç›¸ä¼¼ï¼‰
2. LRM å­˜å‚¨ Q-valuesï¼ˆé•¿åº¦ = n_childrenï¼‰
3. children å¯ä»¥æ˜¯ action å­—ç¬¦ä¸²æˆ–å­ Structon
4. æ··åˆè®°å¿†ï¼šåŒä¸€ä¸ª LRM å­˜å‚¨å¤šç±»åˆ«çš„è·¯ç”±å†³ç­–

è®¾è®¡å“²å­¦ï¼š
- Structure is skeleton, Memory is soul
- å±€éƒ¨è§„åˆ™ï¼Œå…¨å±€æ¶Œç°
- é€‚åº”ä¼˜äºä¼˜åŒ–

Author: Structon Framework
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass, field
import os
import gzip
import struct
import urllib.request
import time


# =============================================================================
# 1. MNIST åŠ è½½
# =============================================================================

def load_mnist(path='./mnist_data'):
    """åŠ è½½ MNIST æ•°æ®é›†"""
    os.makedirs(path, exist_ok=True)
    
    base_url = 'http://yann.lecun.com/exdb/mnist/'
    files = {
        'train_images': 'train-images-idx3-ubyte.gz',
        'train_labels': 'train-labels-idx1-ubyte.gz',
        'test_images': 't10k-images-idx3-ubyte.gz',
        'test_labels': 't10k-labels-idx1-ubyte.gz'
    }
    
    for name, filename in files.items():
        filepath = os.path.join(path, filename)
        if not os.path.exists(filepath):
            print(f"Downloading {filename}...")
            urllib.request.urlretrieve(base_url + filename, filepath)
    
    def read_images(filepath):
        with gzip.open(filepath, 'rb') as f:
            magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
            images = np.frombuffer(f.read(), dtype=np.uint8)
            return images.reshape(num, rows, cols)
    
    def read_labels(filepath):
        with gzip.open(filepath, 'rb') as f:
            magic, num = struct.unpack('>II', f.read(8))
            return np.frombuffer(f.read(), dtype=np.uint8)
    
    train_images = read_images(os.path.join(path, files['train_images']))
    train_labels = read_labels(os.path.join(path, files['train_labels']))
    test_images = read_images(os.path.join(path, files['test_images']))
    test_labels = read_labels(os.path.join(path, files['test_labels']))
    
    return train_images, train_labels, test_images, test_labels


# =============================================================================
# 2. ç‰¹å¾æå–å™¨
# =============================================================================

class StateExtractor:
    """æå– MNIST å›¾åƒçš„çŠ¶æ€ç‰¹å¾"""
    
    def __init__(self):
        self.feature_dim = 25
    
    def extract(self, image: np.ndarray) -> np.ndarray:
        """æå– 25 ç»´ç‰¹å¾"""
        img = image.astype(np.float32) / 255.0
        binary = (img > 0.3).astype(np.float32)
        
        features = []
        
        # 1. æ‹“æ‰‘ç‰¹å¾ (4D)
        n_holes = self._count_holes(binary)
        endpoints = self._find_endpoints(binary)
        junctions = self._find_junctions(binary)
        is_closed = 1.0 if n_holes > 0 else 0.0
        
        features.extend([
            n_holes / 3.0,
            len(endpoints) / 5.0,
            len(junctions) / 3.0,
            is_closed
        ])
        
        # 2. ç«¯ç‚¹ä½ç½® (9D) - 9 å®«æ ¼
        ep_regions = np.zeros(9)
        for y, x in endpoints:
            ry, rx = min(2, y // 10), min(2, x // 10)
            ep_regions[ry * 3 + rx] = 1.0
        features.extend(ep_regions)
        
        # 3. äº¤å‰ç‚¹ä½ç½® (3D) - ä¸Šä¸­ä¸‹
        jc_regions = np.zeros(3)
        for y, x in junctions:
            region = min(2, y // 10)
            jc_regions[region] = 1.0
        features.extend(jc_regions)
        
        # 4. è¾¹ç¼˜æ–¹å‘ (4D)
        h_top = np.sum(binary[:10, :]) / (10 * 28)
        h_bottom = np.sum(binary[18:, :]) / (10 * 28)
        v_left = np.sum(binary[:, :10]) / (28 * 10)
        v_right = np.sum(binary[:, 18:]) / (28 * 10)
        features.extend([h_top, h_bottom, v_left, v_right])
        
        # 5. å¯†åº¦åˆ†å¸ƒ (3D)
        density_top = np.sum(binary[:9, :]) / (9 * 28)
        density_mid = np.sum(binary[9:18, :]) / (9 * 28)
        density_bottom = np.sum(binary[18:, :]) / (10 * 28)
        features.extend([density_top, density_mid, density_bottom])
        
        # 6. è´¨å¿ƒ (2D)
        ys, xs = np.where(binary > 0)
        if len(xs) > 0:
            cx, cy = np.mean(xs) / 28.0, np.mean(ys) / 28.0
        else:
            cx, cy = 0.5, 0.5
        features.extend([cx, cy])
        
        return np.array(features, dtype=np.float32)
    
    def _count_holes(self, binary: np.ndarray) -> int:
        from collections import deque
        
        padded = np.pad(binary, 1, mode='constant', constant_values=0)
        visited = np.zeros_like(padded, dtype=bool)
        
        queue = deque([(0, 0)])
        visited[0, 0] = True
        
        while queue:
            y, x = queue.popleft()
            for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
                ny, nx = y + dy, x + dx
                if 0 <= ny < padded.shape[0] and 0 <= nx < padded.shape[1]:
                    if not visited[ny, nx] and padded[ny, nx] == 0:
                        visited[ny, nx] = True
                        queue.append((ny, nx))
        
        holes = 0
        for y in range(1, padded.shape[0] - 1):
            for x in range(1, padded.shape[1] - 1):
                if padded[y, x] == 0 and not visited[y, x]:
                    holes += 1
                    queue = deque([(y, x)])
                    visited[y, x] = True
                    while queue:
                        cy, cx = queue.popleft()
                        for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
                            ny, nx = cy + dy, cx + dx
                            if not visited[ny, nx] and padded[ny, nx] == 0:
                                visited[ny, nx] = True
                                queue.append((ny, nx))
        
        return holes
    
    def _find_endpoints(self, binary: np.ndarray) -> List[Tuple[int, int]]:
        endpoints = []
        skeleton = binary.copy()
        
        for y in range(1, binary.shape[0] - 1):
            for x in range(1, binary.shape[1] - 1):
                if skeleton[y, x] > 0:
                    neighbors = np.sum(skeleton[y-1:y+2, x-1:x+2]) - skeleton[y, x]
                    if neighbors == 1:
                        endpoints.append((y, x))
        
        return endpoints[:5]
    
    def _find_junctions(self, binary: np.ndarray) -> List[Tuple[int, int]]:
        junctions = []
        skeleton = binary.copy()
        
        for y in range(1, binary.shape[0] - 1):
            for x in range(1, binary.shape[1] - 1):
                if skeleton[y, x] > 0:
                    neighbors = np.sum(skeleton[y-1:y+2, x-1:x+2]) - skeleton[y, x]
                    if neighbors >= 3:
                        junctions.append((y, x))
        
        return junctions[:3]


# =============================================================================
# 3. å…±æŒ¯è®°å¿† (Resonant Memory)
# =============================================================================

class ResonantMemory:
    """
    å…±æŒ¯è®°å¿†ï¼šåŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„æ— æ¢¯åº¦å­¦ä¹ 
    
    å­˜å‚¨ pattern â†’ Q-values æ˜ å°„
    Q-values é•¿åº¦ = n_actionsï¼ˆchildren æ•°é‡ï¼‰
    """
    
    def __init__(
        self,
        key_dim: int,
        n_actions: int,
        capacity: int = 100,
        temperature: float = 0.1,
        lr: float = 0.3,
        similarity_threshold: float = 0.85
    ):
        self.key_dim = key_dim
        self.n_actions = n_actions
        self.capacity = capacity
        self.temperature = temperature
        self.lr = lr
        self.similarity_threshold = similarity_threshold
        
        # è®°å¿†å­˜å‚¨
        self.keys: List[np.ndarray] = []          # pattern keys
        self.values: List[np.ndarray] = []        # Q-values (n_actions ç»´)
        self.access_counts: List[int] = []
        
        # å†»ç»“çŠ¶æ€
        self.frozen: bool = False
        
        # ç»Ÿè®¡
        self.total_queries = 0
        self.total_updates = 0
    
    def query(self, key: np.ndarray) -> Tuple[np.ndarray, float]:
        """
        å…±æŒ¯æŸ¥è¯¢
        
        Returns:
            q_values: å„ action çš„ Q å€¼
            confidence: ç½®ä¿¡åº¦ (0-1)
        """
        self.total_queries += 1
        
        if len(self.keys) == 0:
            return np.zeros(self.n_actions, dtype=np.float32), 0.0
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        key_matrix = np.array(self.keys)
        scores = key_matrix @ key
        
        max_score = float(np.max(scores))
        
        # Softmax åŠ æƒ
        exp_scores = np.exp((scores - max_score) / self.temperature)
        weights = exp_scores / (np.sum(exp_scores) + 1e-8)
        
        # åŠ æƒæ±‚å’Œå¾—åˆ° Q-values
        value_matrix = np.array(self.values)
        q_values = weights @ value_matrix
        
        # æ›´æ–°è®¿é—®è®¡æ•°
        best_idx = int(np.argmax(scores))
        self.access_counts[best_idx] += 1
        
        # ç½®ä¿¡åº¦
        confidence = max(0.0, min(1.0, (max_score - 0.5) * 2))
        
        return q_values.astype(np.float32), confidence
    
    def remember(
        self,
        key: np.ndarray,
        action: int,
        target: float
    ) -> str:
        """
        å†™å…¥è®°å¿†
        
        Returns:
            'update' - æ›´æ–°ç°æœ‰è®°å¿†
            'new' - åˆ›å»ºæ–°è®°å¿†
            'frozen' - å†»ç»“çŠ¶æ€ï¼Œæ‹’ç»å†™å…¥
        """
        if self.frozen:
            return 'frozen'
        
        self.total_updates += 1
        
        # æŸ¥æ‰¾ç›¸ä¼¼è®°å¿†
        best_idx = -1
        best_score = -1.0
        
        if len(self.keys) > 0:
            key_matrix = np.array(self.keys)
            scores = key_matrix @ key
            best_idx = int(np.argmax(scores))
            best_score = float(scores[best_idx])
            
            if best_score < self.similarity_threshold:
                best_idx = -1
        
        if best_idx >= 0:
            # æ›´æ–°ç°æœ‰è®°å¿†
            old_val = self.values[best_idx][action]
            self.values[best_idx][action] = old_val + self.lr * (target - old_val)
            self.access_counts[best_idx] += 1
            return 'update'
        else:
            # å®¹é‡ç®¡ç†
            if len(self.keys) >= self.capacity:
                min_idx = int(np.argmin(self.access_counts))
                self.keys.pop(min_idx)
                self.values.pop(min_idx)
                self.access_counts.pop(min_idx)
            
            # åˆ›å»ºæ–°è®°å¿†
            new_q = np.zeros(self.n_actions, dtype=np.float32)
            if len(self.keys) > 0:
                # ç»§æ‰¿å½“å‰æŸ¥è¯¢ç»“æœ
                new_q, _ = self.query(key)
                new_q = new_q.copy()
            new_q[action] = target
            
            self.keys.append(key.copy())
            self.values.append(new_q)
            self.access_counts.append(1)
            return 'new'
    
    def freeze(self):
        """å†»ç»“è®°å¿†"""
        self.frozen = True
    
    def unfreeze(self):
        """è§£å†»è®°å¿†"""
        self.frozen = False
    
    @property
    def size(self) -> int:
        return len(self.keys)
    
    def get_stats(self) -> Dict:
        return {
            'size': self.size,
            'capacity': self.capacity,
            'capacity_ratio': self.size / self.capacity if self.capacity > 0 else 0,
            'total_queries': self.total_queries,
            'total_updates': self.total_updates,
            'frozen': self.frozen
        }


# =============================================================================
# 4. ç»Ÿä¸€çš„ Structon
# =============================================================================

class Structon:
    """
    ç»Ÿä¸€çš„ Structon - è‡ªç›¸ä¼¼åˆ†å½¢å•å…ƒ
    
    æ¯ä¸ª Structonï¼š
    - æœ‰ LRM å­˜å‚¨è·¯ç”±å†³ç­–ï¼ˆQ-valuesï¼‰
    - children å¯ä»¥æ˜¯ action å­—ç¬¦ä¸²æˆ–å­ Structon
    - ç”¨éšæœºæŠ•å½±ç¼–ç è¾“å…¥
    """
    
    _id_counter = 0
    
    def __init__(
        self,
        children: List[Union[str, 'Structon']],
        capacity: int = 100,
        key_dim: int = 16,
        full_dim: int = 25,
        temperature: float = 0.1,
        lr: float = 0.3,
        similarity_threshold: float = 0.85
    ):
        Structon._id_counter += 1
        self.id = f"S{Structon._id_counter:03d}"
        
        self.children = children
        self.n_actions = len(children)
        
        # éšæœºæŠ•å½±
        self.full_dim = full_dim
        self.key_dim = key_dim
        self.projector = np.random.randn(full_dim, key_dim).astype(np.float32)
        self.projector /= (np.linalg.norm(self.projector, axis=0, keepdims=True) + 1e-8)
        
        # å…±æŒ¯è®°å¿†
        self.lrm = ResonantMemory(
            key_dim=key_dim,
            n_actions=self.n_actions,
            capacity=capacity,
            temperature=temperature,
            lr=lr,
            similarity_threshold=similarity_threshold
        )
        
        # å‚æ•°å­˜å‚¨ï¼ˆç”¨äºåˆ›å»ºå­èŠ‚ç‚¹ï¼‰
        self.capacity = capacity
        self.temperature = temperature
        self.lr = lr
        self.similarity_threshold = similarity_threshold
        
        # ç»Ÿè®¡
        self.total_queries = 0
        self.total_learns = 0
    
    def _encode(self, pattern: np.ndarray) -> np.ndarray:
        """éšæœºæŠ•å½±ç¼–ç """
        key = pattern.astype(np.float32) @ self.projector
        norm = np.linalg.norm(key)
        if norm > 1e-8:
            key /= norm
        return key
    
    @property
    def frozen(self) -> bool:
        return self.lrm.frozen
    
    def freeze(self):
        """å†»ç»“ï¼ˆåœæ­¢å­¦ä¹ ï¼Œä½†ä»å¯æŸ¥è¯¢ï¼‰"""
        self.lrm.freeze()
    
    def unfreeze(self):
        """è§£å†»"""
        self.lrm.unfreeze()
    
    def is_leaf(self) -> bool:
        """æ˜¯å¦æ˜¯å¶å­èŠ‚ç‚¹ï¼ˆchildren å…¨æ˜¯å­—ç¬¦ä¸²ï¼‰"""
        return all(isinstance(c, str) for c in self.children)
    
    def query(self, pattern: np.ndarray) -> Tuple[int, np.ndarray, float]:
        """
        æŸ¥è¯¢ï¼šé€‰æ‹©å“ªä¸ª child
        
        Returns:
            action_idx: é€‰æ‹©çš„ child ç´¢å¼•
            q_values: æ‰€æœ‰ children çš„ Q å€¼
            confidence: ç½®ä¿¡åº¦
        """
        self.total_queries += 1
        key = self._encode(pattern)
        q_values, confidence = self.lrm.query(key)
        action_idx = int(np.argmax(q_values))
        return action_idx, q_values, confidence
    
    def execute(self, pattern: np.ndarray) -> Tuple[str, float]:
        """
        æ‰§è¡Œï¼šé€’å½’æŸ¥è¯¢ç›´åˆ°å¾—åˆ° action
        
        Returns:
            action: æœ€ç»ˆé€‰æ‹©çš„åŠ¨ä½œï¼ˆå­—ç¬¦ä¸²ï¼‰
            confidence: ç½®ä¿¡åº¦
        """
        action_idx, q_values, confidence = self.query(pattern)
        child = self.children[action_idx]
        
        if isinstance(child, str):
            # å¶å­ï¼šè¿”å› action
            return child, confidence
        else:
            # ä¸­é—´èŠ‚ç‚¹ï¼šé€’å½’
            return child.execute(pattern)
    
    def learn(
        self,
        pattern: np.ndarray,
        true_action: str,
        reward: float = 1.0
    ) -> str:
        """
        å­¦ä¹ ï¼šæ›´æ–°è·¯ç”±å†³ç­–
        
        Args:
            pattern: è¾“å…¥æ¨¡å¼
            true_action: æ­£ç¡®çš„åŠ¨ä½œï¼ˆå­—ç¬¦ä¸²ï¼‰
            reward: å¥–åŠ±å€¼
        
        Returns:
            çŠ¶æ€ä¿¡æ¯
        """
        self.total_learns += 1
        key = self._encode(pattern)
        
        # æ‰¾åˆ° true_action å¯¹åº”çš„ child ç´¢å¼•
        target_idx = None
        for i, child in enumerate(self.children):
            if isinstance(child, str):
                if child == true_action:
                    target_idx = i
                    break
            else:
                # å­ Structonï¼šæ£€æŸ¥å®ƒèƒ½å¦åˆ°è¾¾ true_action
                # ç®€åŒ–ï¼šå‡è®¾æ¯ä¸ªæ•°å­—æœ€ç»ˆç”±å¯¹åº”ç´¢å¼•çš„ child å¤„ç†
                if str(i) == true_action:
                    target_idx = i
                    break
        
        if target_idx is None:
            # å¦‚æœ children æ˜¯æ•°å­—å­—ç¬¦ä¸²
            try:
                target_idx = int(true_action)
            except:
                return "invalid_action"
        
        if target_idx >= self.n_actions:
            return "invalid_action"
        
        # æ›´æ–° LRM
        status = self.lrm.remember(key, target_idx, reward)
        
        # å¦‚æœ child æ˜¯ Structonï¼Œé€’å½’å­¦ä¹ 
        child = self.children[target_idx]
        if isinstance(child, Structon):
            child.learn(pattern, true_action, reward)
        
        return status
    
    def predict(self, pattern: np.ndarray) -> Tuple[str, float]:
        """é¢„æµ‹ï¼ˆexecute çš„åˆ«åï¼‰"""
        return self.execute(pattern)
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'id': self.id,
            'n_children': self.n_actions,
            'is_leaf': self.is_leaf(),
            'frozen': self.frozen,
            'total_queries': self.total_queries,
            'total_learns': self.total_learns,
            'lrm': self.lrm.get_stats()
        }
        
        if not self.is_leaf():
            stats['children'] = []
            for child in self.children:
                if isinstance(child, Structon):
                    stats['children'].append(child.get_stats())
                else:
                    stats['children'].append({'action': child})
        
        return stats
    
    def count_nodes(self) -> int:
        """ç»Ÿè®¡èŠ‚ç‚¹æ•°é‡"""
        count = 1
        for child in self.children:
            if isinstance(child, Structon):
                count += child.count_nodes()
        return count
    
    def depth(self) -> int:
        """è·å–æ·±åº¦"""
        if self.is_leaf():
            return 1
        
        max_child_depth = 0
        for child in self.children:
            if isinstance(child, Structon):
                max_child_depth = max(max_child_depth, child.depth())
        
        return 1 + max_child_depth
    
    def total_memories(self) -> int:
        """ç»Ÿè®¡æ€»è®°å¿†æ•°"""
        count = self.lrm.size
        for child in self.children:
            if isinstance(child, Structon):
                count += child.total_memories()
        return count
    
    def print_tree(self, indent: int = 0):
        """æ‰“å°æ ‘ç»“æ„"""
        prefix = "  " * indent
        
        # å›¾æ ‡
        if self.is_leaf():
            icon = "ğŸŒ¿"
            role = "Leaf"
        elif self.frozen:
            icon = "â„ï¸"
            role = "Frozen"
        else:
            icon = "ğŸ”¥"
            role = "Active"
        
        print(f"{prefix}{icon} {self.id} ({role}) "
              f"[mem:{self.lrm.size}/{self.capacity}, "
              f"children:{self.n_actions}]")
        
        # æ˜¾ç¤ºéƒ¨åˆ† Q-values
        if self.lrm.size > 0:
            for i, (key, val) in enumerate(zip(self.lrm.keys[:2], self.lrm.values[:2])):
                best_action = int(np.argmax(val))
                print(f"{prefix}  â””â”€ patternâ†’{best_action} "
                      f"(Q: {val[best_action]:.2f})")
            if self.lrm.size > 2:
                print(f"{prefix}  â””â”€ ... ({self.lrm.size - 2} more)")
        
        # é€’å½’æ‰“å°å­èŠ‚ç‚¹
        for i, child in enumerate(self.children):
            if isinstance(child, Structon):
                child.print_tree(indent + 1)


# =============================================================================
# 5. Vision System
# =============================================================================

class StructonVisionSystem:
    """
    Structon è§†è§‰ç³»ç»Ÿ - MNIST åˆ†ç±»
    
    å•å±‚ Structonï¼Œ10 ä¸ª children å¯¹åº” 10 ä¸ªæ•°å­—
    """
    
    def __init__(
        self,
        capacity: int = 100,
        key_dim: int = 16,
        full_dim: int = 25,
        temperature: float = 0.1,
        lr: float = 0.3,
        similarity_threshold: float = 0.85
    ):
        self.extractor = StateExtractor()
        
        # åˆ›å»º root Structon
        # children = ["0", "1", ..., "9"]
        self.root = Structon(
            children=[str(i) for i in range(10)],
            capacity=capacity,
            key_dim=key_dim,
            full_dim=full_dim,
            temperature=temperature,
            lr=lr,
            similarity_threshold=similarity_threshold
        )
        
        self.capacity = capacity
        self.key_dim = key_dim
        self.full_dim = full_dim
        
        # ç»Ÿè®¡
        self.train_count = 0
        self.correct_count = 0
    
    def predict(self, image: np.ndarray) -> Tuple[str, float]:
        """é¢„æµ‹"""
        state = self.extractor.extract(image)
        return self.root.predict(state)
    
    def train_one(self, image: np.ndarray, true_label: str, reward: float = 1.0) -> Tuple[str, bool]:
        """è®­ç»ƒä¸€ä¸ªæ ·æœ¬"""
        self.train_count += 1
        
        state = self.extractor.extract(image)
        
        # é¢„æµ‹
        predicted, confidence = self.root.predict(state)
        correct = (predicted == true_label)
        
        if correct:
            self.correct_count += 1
        
        # å­¦ä¹ 
        status = self.root.learn(state, true_label, reward)
        
        return status, correct
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n=== Structon Vision System ===")
        print(f"è®­ç»ƒæ ·æœ¬: {self.train_count}")
        if self.train_count > 0:
            print(f"è®­ç»ƒå‡†ç¡®ç‡: {self.correct_count/self.train_count*100:.1f}%")
        print(f"èŠ‚ç‚¹æ•°: {self.root.count_nodes()}")
        print(f"æ·±åº¦: {self.root.depth()}")
        print(f"æ€»è®°å¿†: {self.root.total_memories()}")
        
        print(f"\n=== æ ‘ç»“æ„ ===")
        self.root.print_tree()


# =============================================================================
# 6. å®éªŒ
# =============================================================================

def run_experiment(
    n_per_class: int = 50,
    n_test: int = 500,
    capacity: int = 100,
    key_dim: int = 16,
    temperature: float = 0.1,
    lr: float = 0.3,
    similarity_threshold: float = 0.85
):
    """è¿è¡Œå®éªŒ"""
    print("=" * 70)
    print("Structon Vision v7.20 - ç»Ÿä¸€åˆ†å½¢æ¶æ„")
    print("=" * 70)
    print(f"\nå‚æ•°:")
    print(f"  capacity={capacity}, key_dim={key_dim}")
    print(f"  temperature={temperature}, lr={lr}")
    print(f"  similarity_threshold={similarity_threshold}")
    print(f"  æ¯ç±»è®­ç»ƒ: {n_per_class}, æµ‹è¯•: {n_test}")
    
    print("\næ ¸å¿ƒæ”¹å˜:")
    print("  1. ç»Ÿä¸€ Structonï¼šæ¯ä¸ªèŠ‚ç‚¹ç»“æ„ç›¸åŒ")
    print("  2. LRM å­˜ Q-valuesï¼šé•¿åº¦ = n_children = 10")
    print("  3. æ··åˆè®°å¿†ï¼šåŒä¸€ LRM å­˜å¤šç±»åˆ«è·¯ç”±å†³ç­–")
    print("  4. ç›¸ä¼¼ pattern â†’ ç›¸ä¼¼ Q-valuesï¼ˆå…±æŒ¯ï¼‰")
    
    print("\nLoading MNIST...")
    train_images, train_labels, test_images, test_labels = load_mnist()
    
    system = StructonVisionSystem(
        capacity=capacity,
        key_dim=key_dim,
        full_dim=25,
        temperature=temperature,
        lr=lr,
        similarity_threshold=similarity_threshold
    )
    
    print(f"\n=== è®­ç»ƒï¼ˆæ··åˆé¡ºåºï¼‰===")
    t0 = time.time()
    
    # æ”¶é›†è®­ç»ƒæ ·æœ¬ï¼ˆæ¯ç±» n_per_class ä¸ªï¼‰
    train_indices = []
    for digit in range(10):
        indices = np.where(train_labels == digit)[0][:n_per_class]
        train_indices.extend(indices)
    
    # æ‰“ä¹±é¡ºåº
    np.random.shuffle(train_indices)
    
    total_samples = len(train_indices)
    correct = 0
    
    for i, idx in enumerate(train_indices):
        status, is_correct = system.train_one(
            train_images[idx],
            str(train_labels[idx])
        )
        if is_correct:
            correct += 1
        
        if (i + 1) % 100 == 0:
            print(f"  è®­ç»ƒ {i+1}/{total_samples}, "
                  f"å‡†ç¡®ç‡: {correct/(i+1)*100:.1f}%, "
                  f"è®°å¿†: {system.root.lrm.size}/{capacity}")
    
    print(f"\nè®­ç»ƒå®Œæˆ: {time.time()-t0:.1f}ç§’")
    
    system.print_stats()
    
    # æµ‹è¯•
    print(f"\n=== æµ‹è¯• {n_test} æ ·æœ¬ ===")
    results = {str(d): {'correct': 0, 'total': 0} for d in range(10)}
    test_indices = np.random.choice(len(test_images), n_test, replace=False)
    
    t0 = time.time()
    for idx in test_indices:
        predicted, confidence = system.predict(test_images[idx])
        true_label = str(test_labels[idx])
        
        results[true_label]['total'] += 1
        if predicted == true_label:
            results[true_label]['correct'] += 1
    
    print(f"æµ‹è¯•å®Œæˆ: {time.time()-t0:.1f}ç§’")
    
    total_correct = sum(r['correct'] for r in results.values())
    total_samples = sum(r['total'] for r in results.values())
    
    print(f"\næ€»å‡†ç¡®ç‡: {total_correct/total_samples*100:.1f}%")
    print("\nå„æ•°å­—:")
    for d in range(10):
        r = results[str(d)]
        if r['total'] > 0:
            acc = r['correct'] / r['total'] * 100
            print(f"  {d}: {acc:.1f}% ({r['correct']}/{r['total']})")
    
    return system


# =============================================================================
# ä¸»å…¥å£
# =============================================================================

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--per-class', type=int, default=50)
    parser.add_argument('--test', type=int, default=500)
    parser.add_argument('--capacity', type=int, default=100)
    parser.add_argument('--key-dim', type=int, default=16)
    parser.add_argument('--temperature', type=float, default=0.1)
    parser.add_argument('--lr', type=float, default=0.3)
    parser.add_argument('--threshold', type=float, default=0.85)
    args = parser.parse_args()
    
    run_experiment(
        n_per_class=args.per_class,
        n_test=args.test,
        capacity=args.capacity,
        key_dim=args.key_dim,
        temperature=args.temperature,
        lr=args.lr,
        similarity_threshold=args.threshold
    )
